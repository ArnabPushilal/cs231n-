# NOTES for this assigment

Some helpful links I found along the way for the CS231n standord course

**Course link for contents of assignment and lecture modules**
https://cs231n.github.io/


**Gradient Computation for the Linear Classifier with a Soft Max cross entory loss**
https://madalinabuzau.github.io/2016/11/29/gradient-descent-on-a-softmax-cross-entropy-cost-function.html - This was not available or not explicty mentioned in the course lectures hence I had to dig this out , as I was just starting out. This gave me an intuition of computing Gradients for other loss functions as well.

EDIT ** Lesson Learned watch till lecture 4 before starting the assignment, things will be more clear about Gradients. Turns out it was a simple chain rule application


**Making Chain rule & gradient Easier for Neural Nets**
http://cs231n.stanford.edu/vecDerivs.pdf - I followed the advice mentioned and coded out the classifier with very small batches to see what was going on in each matrice computation. This helped me visualize the problem . You will see that I have made such practice cells around the notebooks

